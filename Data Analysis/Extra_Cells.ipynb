{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentAutoencoder(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(RecurrentAutoencoder, self).__init__()\n",
    "        self.layer_sizes = [512, 128]\n",
    "        self.num_features = num_features\n",
    "\n",
    "        self.encode_rnn1 = nn.LSTM(\n",
    "            input_size=self.num_features,\n",
    "            hidden_size=self.layer_sizes[0],\n",
    "            num_layers=1,\n",
    "            batch_first=True\n",
    "        ).cuda()\n",
    "\n",
    "        self.encode_rnn2= nn.LSTM(\n",
    "            input_size=self.layer_sizes[0],\n",
    "            hidden_size=self.layer_sizes[1],\n",
    "            num_layers=1,\n",
    "            batch_first=True\n",
    "        ).cuda()\n",
    "\n",
    "        self.decode_rnn1 = nn.LSTM(\n",
    "            input_size=self.layer_sizes[1],\n",
    "            hidden_size=self.layer_sizes[1],\n",
    "            num_layers=1,\n",
    "            batch_first=True\n",
    "        ).cuda()\n",
    "\n",
    "        self.decode_rnn2 = nn.LSTM(\n",
    "            input_size=self.layer_sizes[1],\n",
    "            hidden_size=self.layer_sizes[0],\n",
    "            num_layers=1,\n",
    "            batch_first=True\n",
    "        ).cuda()\n",
    "\n",
    "        self.output_layer = nn.Linear(self.layer_sizes[0], self.num_features).cuda()\n",
    "\n",
    "    def forward(self, x):\n",
    "        seq_len = x.shape[1]\n",
    "        print(x.shape)\n",
    "        x, (_, _) = self.encode_rnn1(x)\n",
    "        _, (encoded, _) = self.encode_rnn2(x)\n",
    "        \n",
    "        encoded = encoded.repeat(seq_len, self.num_features)\n",
    "        encoded = encoded.reshape((self.num_features, seq_len, self.layer_sizes[1]))\n",
    "        encoded, (_, _) = self.decode_rnn1(encoded)\n",
    "        encoded, (_, _) = self.decode_rnn2(encoded)\n",
    "        encoded = encoded.reshape((seq_len, self.layer_sizes[0]))\n",
    "        return self.output_layer(encoded).reshape((1, seq_len, 1))\n",
    "    \n",
    "# def MSETripletLoss(X, encoded_X, encoded_pos, encoded_neg):\n",
    "#     CE_loss = nn.MSE(encoded_X, X)\n",
    "#     sub = torch.subtract(torch.dot(encoded_X, encoded_neg), torch.dot(encoded_X, encoded_pos))\n",
    "#     exp = torch.exp(sub)\n",
    "#     triplet_loss = torch.log(torch.add(1, exp))\n",
    "#     return torch.add(CE_loss, triplet_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, out_dim, h_dims, h_activ, out_activ):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        layer_dims = [input_dim] + h_dims + [out_dim]\n",
    "        self.num_layers = len(layer_dims) - 1\n",
    "        self.layers = nn.ModuleList()\n",
    "        for index in range(self.num_layers):\n",
    "            layer = nn.Linear(\n",
    "                layer_dims[index],\n",
    "                layer_dims[index + 1],\n",
    "            )\n",
    "            self.layers.append(layer)\n",
    "\n",
    "        self.h_activ, self.out_activ = h_activ, out_activ   \n",
    "\n",
    "    def forward(self, x):\n",
    "        for index, layer in enumerate(self.layers):\n",
    "            x = layer(x)\n",
    "\n",
    "            if self.h_activ and index < self.num_layers - 1:\n",
    "                x = self.h_activ(x)\n",
    "            elif self.out_activ and index == self.num_layers - 1:\n",
    "                return self.out_activ(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_dim, out_dim, h_dims, h_activ):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        layer_dims = [input_dim] + h_dims + [h_dims[-1]]\n",
    "        self.num_layers = len(layer_dims) - 1\n",
    "        self.layers = nn.ModuleList()\n",
    "        for index in range(self.num_layers):\n",
    "            layer = nn.Linear(\n",
    "                layer_dims[index],\n",
    "                layer_dims[index + 1],\n",
    "            )\n",
    "            self.layers.append(layer)\n",
    "\n",
    "        self.h_activ = h_activ\n",
    "        self.dense_matrix = nn.Parameter(\n",
    "            torch.rand((layer_dims[-1], out_dim), dtype=torch.float),\n",
    "            requires_grad=True\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        for index, layer in enumerate(self.layers):\n",
    "            x = layer(x)\n",
    "\n",
    "            if self.h_activ and index < self.num_layers - 1:\n",
    "                x = self.h_activ(x)\n",
    "\n",
    "        return torch.mm(x, self.dense_matrix)\n",
    "\n",
    "\n",
    "######\n",
    "# MAIN\n",
    "######\n",
    "\n",
    "\n",
    "class AE(nn.Module):\n",
    "    def __init__(self, input_dim, encoding_dim, h_dims=[], h_activ=nn.ReLU(),\n",
    "                 out_activ=nn.Tanh()):\n",
    "        super(AE, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(input_dim, encoding_dim, h_dims, h_activ,\n",
    "                               out_activ).cuda()\n",
    "        self.decoder = Decoder(encoding_dim, input_dim, h_dims[::-1],\n",
    "                               h_activ).cuda()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hidden_dims, activ):\n",
    "        super(VariationalEncoder, self).__init__()\n",
    "        self.dims = [input_dim] + hidden_dims + [emb_dim]\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.activ = activ\n",
    "        for dim1, dim2 in zip(self.dims, self.dims[1:-1]):\n",
    "            layer = nn.Linear(dim1, dim2).cuda()\n",
    "            self.layers.append(layer)\n",
    "        \n",
    "        self.mu_layer = nn.Linear(self.dims[-2], self.dims[-1])\n",
    "        self.sigma_layer = nn.Linear(self.dims[-2], self.dims[-1])\n",
    "\n",
    "        self.N = torch.distributions.Normal(0, 1)\n",
    "        self.N.loc = self.N.loc.cuda()  # hack to get sampling on the GPU\n",
    "        self.N.scale = self.N.scale.cuda()\n",
    "        self.kl = 0\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = self.activ(layer(x))\n",
    "\n",
    "        mu = self.mu_layer(x)\n",
    "        sigma = torch.exp(self.sigma_layer(x))\n",
    "        z = mu + sigma*self.N.sample(mu.shape)\n",
    "        self.kl = (sigma**2 + mu**2 - torch.log(sigma) - 1/2).sum()\n",
    "        return z\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hidden_dims, activ):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.dims = [input_dim] + hidden_dims + [emb_dim]\n",
    "        self.dims = self.dims[::-1]\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.activ = activ\n",
    "        for dim1, dim2 in zip(self.dims, self.dims[1:]):\n",
    "            layer = nn.Linear(dim1, dim2).cuda()\n",
    "            self.layers.append(layer)\n",
    "\n",
    "    def forward(self, z):\n",
    "        for layer in self.layers[:-1]:\n",
    "            z = self.activ(layer(z))\n",
    "        z = self.layers[-1](z)\n",
    "        return z\n",
    "\n",
    "class VariationalAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hidden_dims=[], activ=F.relu):\n",
    "        super(VariationalAutoencoder, self).__init__()\n",
    "        self.encoder = VariationalEncoder(input_dim, emb_dim, hidden_dims, activ)\n",
    "        self.decoder = Decoder(input_dim, emb_dim, hidden_dims, activ)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        return self.decoder(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self, margin=1.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        \n",
    "    def calc_euclidean(self, x1, x2):\n",
    "        return (x1 - x2).pow(2).sum(1)\n",
    "    \n",
    "    def forward(self, anchor: torch.Tensor, positive: torch.Tensor, negative: torch.Tensor) -> torch.Tensor:\n",
    "        distance_positive = self.calc_euclidean(anchor, positive)\n",
    "        distance_negative = self.calc_euclidean(anchor, negative)\n",
    "        losses_positive = torch.pow(distance_positive, 2) / 2\n",
    "        losses_negative = torch.pow(1 / distance_negative, 2) / 2\n",
    "\n",
    "        return (losses_positive + losses_negative).mean()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
